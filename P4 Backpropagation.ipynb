{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    e = 2.71828\n",
    "    F = 1/(1 + e**(-z))\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(object):\n",
    "\n",
    "    def __init__(self, bias, weights):\n",
    "        self.bias = bias\n",
    "        self.weights = weights\n",
    "        self.outputs = None\n",
    "        self.errors = None\n",
    "        self.deltaWeight = []\n",
    "        self.deltaBias = None\n",
    "        self.hiddenError = None\n",
    "        self.previousLayer = None\n",
    "        self.hidden = True\n",
    "        \n",
    "    # Deze functie geeft de eigenschappen van de neuron weer.   \n",
    "    def __str__(self): \n",
    "        return 'Neuron(Bias=' + str(self.bias) + ', Weights=' + str(self.weights) + ', inputs=' + str(self.inputs) + ', outputs=' + str(self.outputs)+ ', Errors=' + str(self.errors)\n",
    "    \n",
    "    # Haalt de errors op van de neuron\n",
    "    def get_errors(self):\n",
    "        return self.errors\n",
    "    \n",
    "    # Haalt de hiddenErrors op van de neuron\n",
    "    def get_hiddenError(self):\n",
    "        return self.hiddenError\n",
    "    \n",
    "    # Activatie functie van de neuron\n",
    "    def activate(self, inputs):\n",
    "        total = 0\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        # Berekent de som en telt de bias er bij op\n",
    "        for i in range(len(self.inputs)):\n",
    "            total += self.inputs[i] * self.weights[i]\n",
    "        \n",
    "        total = total + self.bias\n",
    "        \n",
    "        # Voert de sigmoid functie uit over het totaal\n",
    "        self.outputs = sigmoid(total)\n",
    "        return sigmoid(total)\n",
    "    \n",
    "    # Berekent de error van een neuron in de output laag\n",
    "    def error(self, target):\n",
    "        error = self.outputs * (1-self.outputs) * -(target - self.outputs)\n",
    "        self.errors = error\n",
    "        return error\n",
    "    \n",
    "    def gradient(self, connectedNeuron):\n",
    "        gradient = self.outputs * connectedNeuron.get_errors\n",
    "        self.gradient[i] = gradient\n",
    "        return gradient\n",
    "    \n",
    "    \n",
    "    # berekent de aanpassing aan een weight.\n",
    "    def deltaWeights(self, learningrate):\n",
    "        self.deltaWeight = []\n",
    "        \n",
    "        # Loopt over de vorige laag heen en kent een specifieke neuron toe.\n",
    "        for i in range(len(self.previousLayer.neurons)):\n",
    "            connectedNeuron = self.previousLayer.neurons[i]\n",
    "            \n",
    "            # Loopt over de weights\n",
    "            for j in range(len(self.weights)):\n",
    "                \n",
    "                # Checkt of de neuron waar deze aan vast zit een Error heeft (een output neuron is)\n",
    "                if connectedNeuron.hidden == False:\n",
    "                    deltaweight = learningrate * self.outputs * connectedNeuron.get_errors()\n",
    "                    self.deltaWeight.append(deltaweight)\n",
    "                \n",
    "                # Als connectedNeuron.hidden True is hebben we te maken met een hidden neuron en gebruikt hij de hidden error\n",
    "                else:\n",
    "                    deltaweight = learningrate * self.outputs * connectedNeuron.get_hiddenError()\n",
    "                    self.deltaWeight.append(deltaweight)\n",
    "                \n",
    "\n",
    "    # berekent het verschil in de bias        \n",
    "    def delta_Bias(self, learningrate):\n",
    "        # Checkt of het een output of hidden neuron is en aan de hand daarvan kiest hij welke error hij gebruikt.\n",
    "        if self.hidden == False:\n",
    "            self.deltaBias = learningrate * self.get_errors()\n",
    "        else:\n",
    "            self.deltaBias = learningrate * get_hiddenError()\n",
    "            \n",
    "    # Voert de veranderingen door aan de weights en biases.\n",
    "    def update(self):\n",
    "        print(self.weights, self.bias) # nog voor testen\n",
    "        \n",
    "        # loopt over alle weights en over de bias en voert de verandering door.\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i]= self.weights[i] - self.deltaWeight[i]\n",
    "        self.bias = self.bias - self.deltaBias\n",
    "    \n",
    "    # Berekent de error van een hiddenNeuron doormiddel van de afgeleide sigmoid. \n",
    "    def errorHiddenNeuron(self, connectedNeurons):\n",
    "        total = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            connectedNeuron = connectedNeurons.neurons[i]\n",
    "            total += connectedNeuron.get_errors() * self.weights[i]\n",
    "            self.hiddenError = self.outputs * (1-self.outputs) * total\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuronlayer(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self, neurons):\n",
    "        self.neurons = neurons     \n",
    "    \n",
    "    # Activatie functie van een Neuronlayer\n",
    "    def activate(self, inputs):\n",
    "        total = []\n",
    "        \n",
    "        #ittereert over de neurons\n",
    "        for i in range(len(self.neurons)):\n",
    "            # Saved welke neuron er aan de beurt is\n",
    "            neuron = self.neurons[i]   \n",
    "            \n",
    "            #Neemt de input en voert de activate functie uit met de waardes die die neuron heeft\n",
    "            total.append(neuron.activate(inputs))\n",
    "              \n",
    "        return total\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronNetwork(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self, neuronLayers):\n",
    "        self.neuronLayers = neuronLayers\n",
    "        self.neuronLayer = None\n",
    "    \n",
    "    # De feedfoward functie van het netwerk\n",
    "    def feed_foward(self, inputs):\n",
    "        # Loopt over de layers heen en houdt bij, bij welke layer hij is.\n",
    "        for i in range(len(self.neuronLayers)):\n",
    "            neuronLayer = self.neuronLayers[i]   \n",
    "            \n",
    "            # output is de uitkomst van de neuronlayer activatie functie de gegeven inputs\n",
    "            output = neuronLayer.activate(inputs)\n",
    "            \n",
    "            # Maakt van de output de nieuwe input voor de volgende iteratie.\n",
    "            inputs = output\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    # Implementatie van backwardpropegation\n",
    "    def propegateBackward(self, target, learningrate):\n",
    "        # Loopt door de layers van achter naar voren en kent de layer toe.\n",
    "        for i in range(len(self.neuronLayers[::-1])):\n",
    "            self.neuronLayer = self.neuronLayers[i]\n",
    "            \n",
    "            # Loopt over de neurons in de neuronlayer.\n",
    "            for j in range(len(self.neuronLayer.neurons)):\n",
    "                neuron = self.neuronLayer.neurons[j]\n",
    "                \n",
    "                # Als i nog 0 is zitten we in de output laag en hebben te maken met een output layer\n",
    "                # en gebruikt hij de functie neuron.error(target)\n",
    "                if i == 0:\n",
    "                    neuron.hidden = False\n",
    "                    neuron.error(target)\n",
    "                \n",
    "                # als i hoger is dan 0 zitten we in een hiddenlayer en gebruikt hij de functie neuron.errorHiddenNeuron \n",
    "                elif i > 0:\n",
    "                    neuron.hidden = True\n",
    "                    neuron.errorHiddenNeuron(self.neuronLayers[i-1])\n",
    "               \n",
    "                neuron.previousLayer = self.neuronLayers[i-1]\n",
    "                \n",
    "                # berekent de het verschil in de weights en bias's\n",
    "                neuron.deltaWeights(learningrate)\n",
    "                neuron.delta_Bias(learningrate)\n",
    "        \n",
    "    \n",
    "    # Deze functie past alle veranderingen toe op de neuronen in het netwerk\n",
    "    def updateNetwork(self):\n",
    "        for i in range(len(self.neuronLayers[::-1])):\n",
    "\n",
    "            self.neuronLayer = self.neuronLayers[i]\n",
    "            \n",
    "            for j in range(len(self.neuronLayer.neurons)):\n",
    "                \n",
    "                neuron = self.neuronLayer.neurons[j]\n",
    "               \n",
    "                neuron.update()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hiddenlayer1 = Neuronlayer([Neuron(1.5 ,[-0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5, 0.5] 1.5\n",
      "[-0.5996936954512968, 0.40030630454870314] 1.3780616118724482\n",
      "[-0.7009806708578037, 0.29901932914219626] 1.2302682132992213\n",
      "[-0.7998631259424432, 0.20013687405755665] 1.1099588974992503\n"
     ]
    }
   ],
   "source": [
    "andGate = NeuronNetwork([Hiddenlayer1],)\n",
    "inputs = [[0,0],[1,0],[0,1],[1,1]]\n",
    "results = []\n",
    "target = [0,0,0,1]\n",
    "learningrate = 1\n",
    "pair = []\n",
    "\n",
    "for j in range(1):\n",
    "    for i in range(len(inputs)):\n",
    "        pair.append(inputs[i])\n",
    "    \n",
    "        pair.append(andGate.feed_foward(inputs[i]))\n",
    "        andGate.propegateBackward(target[i], learningrate)\n",
    "        andGate.updateNetwork() # print nog de weights en bias'es van het testen\n",
    "        \n",
    "        # gemiddelde error berekenen en stopconditie toevoegen\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
